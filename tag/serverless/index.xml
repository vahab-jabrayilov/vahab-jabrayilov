<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>serverless | Vahab Jabrayilov</title><link>https://vjabrayilov.github.io/tag/serverless/</link><atom:link href="https://vjabrayilov.github.io/tag/serverless/index.xml" rel="self" type="application/rss+xml"/><description>serverless</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 18 Jul 2023 00:00:00 +0000</lastBuildDate><image><url>https://vjabrayilov.github.io/media/icon_hufdc9ffe2c12a5bb5ad2cfdfce17ddfaa_56068_512x512_fill_lanczos_center_3.png</url><title>serverless</title><link>https://vjabrayilov.github.io/tag/serverless/</link></image><item><title>Granular Computing</title><link>https://vjabrayilov.github.io/post/granularcomputing/</link><pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate><guid>https://vjabrayilov.github.io/post/granularcomputing/</guid><description>&lt;h2 id="review">Review&lt;/h2>
&lt;p>This paper is by the group of John Ousterhout and introduces the concept of so called “Granular computing”. They define “Granular computing” as the collection of very short-lived (10-100 usecs) tasks. The other main properties are large scale(1k-1M cooperating tasks) and short bursts(1-10 msecs of activity). Authors discuss the challenges coming with the new concept and present a few initial ideas about the required infrastructure to support it.&lt;/p>
&lt;p>In granular computing, applications are composed of a very large number of small tasks running in microsecond scale both in parallel and sequentially, spread across thousands of machines. In addition, they are bursty, harnessing thousands of machines for just a few intense milliseconds of computation. In today’s software systems, overheads are too high to support small tasks efficiently or to scale up and down rapidly. Precisely, granular computing requires software infrastructure that operates at microsecond scale, but today’s systems are designed for millisecond scale.&lt;/p>
&lt;p>Authors defend an extreme approach over an incremental one, which will stimulate innovative design thinking. They introduce real-time data-intensive processing and micro-lambdas as two classes of applications which can be possible by granular computing. It is argued that granular computing will enable real-time data-intensive processing to have smaller latency overhead for invoking requests and higher degree of concurrency. Regarding micro lambdas, it will support tasks three orders of magnitude smaller and will allow lambdas to work together by communicating.&lt;/p>
&lt;p>Low latency is one of the major challenges to overcome. Granular computing will require extremely low latency in task initiation and network communication. It shouldn’t take more than 1 usec to invoke a single task and 100 usecs to initiate tasks in the burst. Microsecond-scale network communication is essential both for fast burst startup and communication among short-lived tasks. Particularly, tail latency matters, since it is difficult to optimize and eliminate infrequent sources of overhead.&lt;/p>
&lt;p>Extreme bursts require to start very quickly by communicating with many servers in parallel and allocate resources on them. The second challenge here is resource utilization. In order to use resources efficiently, non-bursty background tasks must be run during the lulls between bursts, and the system must be able to preempt them very quickly at the start of the next burst.&lt;/p>
&lt;p>Below mentioned overheads show why it is not possible to support granular computing with existing systems:&lt;/p>
&lt;ul>
&lt;li>Creating a thread on Linux takes 10 usecs&lt;/li>
&lt;li>A network RTT between two servers in the same datacenter can take 500 usecs or more when the network is loaded&lt;/li>
&lt;li>Spinning up a Linux container takes hundreds of milliseconds&lt;/li>
&lt;li>Initiating a job that spans a few hundred nodes with Spark, Kubernetes or AWS Lambda can take one second or more.&lt;/li>
&lt;/ul>
&lt;p>Authors mention two major causes of these overheads. First, existing software infrastructure was designed to operate at a millisecond scale, not microsecond. The assumption of disk-based storage permeates much of the design of today’s software. A second problem is high layering. Each layer crossing adds overhead. Granular computing will require a significant re-architecture of the software stack to eliminate layers or bypass them.&lt;/p>
&lt;p>Service concept is introduced as a granular computing unit, which can be either stateless or stateful. This separation based on state helps the underlying infrastructure to leverage its resources efficiently. They also propose two kinds of addressing that will raise the level of abstractions for network communication: service-based addressing and resource-based addressing. In service-based addressing, communication is directed at a particular service, and the infrastructure can load-balance the requests across the service’s instances. It is most appropriate for stateless services. In resource-based addressing, communication is directed to a particular resource, such as a piece of data with a particular data in a key-value store. It makes sense for stateful services. Authors also emphasize the need for efficient group communication with the higher-level addressing mechanisms they propose. Handling bursts are more complex and require sophisticated mechanisms to preempt resources from long running tasks, to isolate short-lived tasks efficiently. Moreover, keeping warm pools to reduce service latency would be unmanageable for large numbers of small tasks since they consume idle resources. Regarding persistence, they favor use of emerging nonvolatile memories or enforcing persistence only occasionally. But the latter isn’t trivial and may require assistance from applications.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://dl.acm.org/doi/pdf/10.1145/3317550.3321447" target="_blank" rel="noopener">Granular Computing&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Go Serverless: Securing Cloud via Serverless Design Patterns</title><link>https://vjabrayilov.github.io/post/serverlessdesignpatterns/</link><pubDate>Tue, 06 Sep 2022 00:00:00 +0000</pubDate><guid>https://vjabrayilov.github.io/post/serverlessdesignpatterns/</guid><description>&lt;h2 id="review">Review&lt;/h2>
&lt;p>Authors have a security background and paper aims at utilizing serverless design patterns in security applications. They solely focus on AWS Lambda, and assume that all the responsibility to secure lambda execution lies on the cloud provider. However, customers are also responsible to secure their communication. They briefly describe six design patterns and how one can use them to develop a security oriented application.&lt;/p>
&lt;p>&lt;strong>Periodic Invocation Pattern&lt;/strong> represents the kind of models that invoke lambda functions periodically by using schedulers. Each function carries out a simple task and reports the execution results to notification channels.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/02f5a2e9-9533-445d-829a-c1a7d700859a/Screenshot_from_2022-09-06_14-27-53.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220906%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220906T112230Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=044ec7568fb7a8a9f2f283d272d2dd4acd85998bc0e780e707f9a237cbe85cb0&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Screenshot%2520from%25202022-09-06%252014-27-53.png%22&amp;amp;x-id=GetObject" alt="img1" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>Event-Driven Pattern&lt;/strong> is where a set of lambda functions subscribe to events from cloud resources. These events trigger the execution of the subscribed lambda function passing the necessary context. It minimizes the cost by invoking lambda functions only when an event occurs and functions scale automatically based on the number of events, providing a scalable design.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/fabec05c-daa5-4473-9127-5138927928aa/Screenshot_from_2022-09-06_14-28-20.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220906%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220906T112316Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=e27f03ead60903ecf5afd8b54a269458f073cdc48ffb2f97bd802e34c0fc6c27&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Screenshot%2520from%25202022-09-06%252014-28-20.png%22&amp;amp;x-id=GetObject" alt="img2" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>Data Transformation Pattern.&lt;/strong> The ETL(extract-transform-load) data processing pipelines usually requires three steps: 1) extract data from a data source, 2) transform data by using frameworks such as Apache Spark or Flink, 3) load the transformed data into a database. Using lambda architecture, data processing tasks can be implemented as lambda functions.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/0f78fc8d-e13c-4097-8bf1-77332e538605/Screenshot_from_2022-09-06_14-28-04.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220906%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220906T112334Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=fbbc6314227bd623be35efd53ca4733f7a071e6479e3b26382f501dfa013622f&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Screenshot%2520from%25202022-09-06%252014-28-04.png%22&amp;amp;x-id=GetObject" alt="img3" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>Data Streaming Pattern.&lt;/strong> A lambda function sits in the path of the data stream and functions either as an aggregator or data partitioner. For example, a lambda can separate an incoming data stream into multiple streams(partition) or merge several incoming streams into one large data stream(aggregation).&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e4d287b2-b415-475b-b317-3ec3d679d784/Screenshot_from_2022-09-06_14-28-27.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220906%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220906T112424Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=55bdc34986556eb7277dc48d88ae9a232c4ceeb24e560ab8dbf273987d00ad8b&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Screenshot%2520from%25202022-09-06%252014-28-27.png%22&amp;amp;x-id=GetObject" alt="img4" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>State Machine Pattern&lt;/strong> enables building a complex, stateful procedure by coordinating a collection of discrete Lambda functions using a tool such as AWS Step Functions. It shouldn’t scale the entire pattern as tasks defined for each state can be scaled up/down individually, Furthermore, the state machine offers a try/catch mechanism so that different or the same functions can be invoked depending on the failure reason.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/401e5618-bacf-485a-96fc-abaaf51434ae/Screenshot_from_2022-09-06_14-28-49.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220906%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220906T112600Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=1d396cf33d4e529556f352fbb586328b98f7e8a7450ccae47770030866b85881&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Screenshot%2520from%25202022-09-06%252014-28-49.png%22&amp;amp;x-id=GetObject" alt="img5" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>&lt;strong>Bundled Pattern&lt;/strong> combines two or more of the previously described patterns together by easily passing events sequentially between them. It resembles UNIX pipelines, where each function is small, precise and does one thing, but true power comes from chaining these together.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/fc8aa752-ef51-453f-a570-3b4485f4b24c/Screenshot_from_2022-09-06_14-28-33.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220906%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220906T112614Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=e27314a11b27d0a8f1eda160733388842ce62fece1595ef21542426424c095b0&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Screenshot%2520from%25202022-09-06%252014-28-33.png%22&amp;amp;x-id=GetObject" alt="img6" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Authors show the time to start a lambda function(50-100ms) as a primary disadvantage. But lower prices for short running functions and better scalability are advantages.&lt;/p>
&lt;p>In later sections of the paper they describe a threat intelligence platform built upon the above mentioned design patterns, which is not interesting for our purpose.&lt;/p>
&lt;p>Authors also discuss some restrictions of current lambda design and offer possible solutions. Time bound execution is highlighted as one of the resource constraints and it can be avoided by splitting the original task across the multiple executions, but it is not possible for all workloads. They describe a proper solution as to either increase the execution time or to automatically pass state between executions so that the task can continue in another execution with the previous state. Lambda also suffers from lack of computing power. They argue that it would be better to have CPU limits configurable and support for GPUs in AWS Lambda. Moreover, lack of event tracing is emphasized by the authors.&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.usenix.org/conference/hotcloud18/presentation/hong" target="_blank" rel="noopener">Go Serverless: Securing Cloud via Serverless Design Patterns&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Will Serverless End the Dominance of Linux in the Cloud? HotOS’17</title><link>https://vjabrayilov.github.io/post/endoflinux/</link><pubDate>Mon, 05 Sep 2022 00:00:00 +0000</pubDate><guid>https://vjabrayilov.github.io/post/endoflinux/</guid><description>&lt;h2 id="review">Review&lt;/h2>
&lt;p>It’s a very short read and one of the early works. The main topic of discussion is the shortcomings of the Linux kernel for the current serverless paradigm. They argue that native container abstraction is ill-suited to be run as a unit of execution for serverless. They show that bypassing the kernel with unikernels can yield at least a factor of 6 better latency and throughput. While the unit of execution in the cloud shrinks, the complexity of the kernel is growing. It’s hard to introduce new abstractions to the kernel as it takes a lot of development investment and the kernel and its community have an inertia towards fast development.&lt;/p>
&lt;p>There are 3 potential approaches to accommodate the serverless in the cloud:&lt;/p>
&lt;ul>
&lt;li>Modify or extend the kernel&lt;/li>
&lt;li>Bypass the kernel&lt;/li>
&lt;li>Replace the kernel&lt;/li>
&lt;/ul>
&lt;p>Very little of the current complexity of the kernel is required for serverless. Two main requirements for the serverless are well isolation from the other tenants as well as host platform, and lambda actions must perform well. The first one removes the solely implementation on top of the native linux processes from the scene. The latter one has two main constituents, low latency and higher throughput. According to the authors, the target goal for the latency is to fetch and start any action under 100ms without any cached state. To cover the financial objectives, achievable throughput should be at least 125.23 actions per second(One can see a back of the envelope calculation in the paper; simply they do calculations based on the pricing of AWS Lambda and EC2).&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/fec8f177-e353-425b-a0fa-2e682f023448/Screenshot_from_2022-09-06_12-43-19.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220906%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220906T084434Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=055a2800d2ccf91387a10acdde046d84103bda37b5ea19c5f73e70a99c729240&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Screenshot%2520from%25202022-09-06%252012-43-19.png%22&amp;amp;x-id=GetObject" alt="img1" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Enhancing the Linux kernel and its container-related capabilities is the favored approach by the industry due to the large investment and dependency on the kernel itself. Moreover, containers are the most popular configuration and existing unit of execution in the current systems. To introduce the support for containers, the Linux kernel underwent major changes to include new abstractions like cgroups and namespaces. But the next significant changes can take longer, because the complexity affects implementation time. It is either hard to implement something in the kernel, and/or too hard to optimize the relevant code paths in the kernel, and/or too hard to secure the kernel.&lt;/p>
&lt;p>The second approach is to bypass the complexity of the kernel and add another layer from which actions(lambda’s) can be started. It can be either achieved on top of hypervisor or unikernel monitors. Bypassing the kernel is commonplace for data plane network services using hardware-level virtualization and software frameworks like DPDK.&lt;/p>
&lt;p>Replacing the kernel with a new and custom designed for serverless type workloads is the way authors emphasize. They serve following alternative design considerations for the new kernel:
Non -preemptive scheduling
Limited set of I/O related calls
No IPC
No process synchronization&lt;/p>
&lt;p>To support their arguments, they do a very simple experiment, running a simple “Hello” example in 3 ways. The baseline is running “echo “Hello”” as a native process, to experiment the containerization they run a similar binary inside the most minimal container via runc, statically linking the binary, without all the overhead of container runtime(Not using docker, networking, and etc.). To show the effect of kernel bypass, a unikernel(ukvm) running Solo5/ukvm is used. Results support the above mentioned arguments.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/aa8d7914-6ff6-4229-85cc-ae94161c503a/Screenshot_from_2022-09-06_12-40-34.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220906%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20220906T084345Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=e1132f5068c939c24f4338ffa78dd3b5ce06206241eaf41c94ad398cc21169e9&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Screenshot%2520from%25202022-09-06%252012-40-34.png%22&amp;amp;x-id=GetObject" alt="img2" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://dl.acm.org/doi/pdf/10.1145/3102980.3103008" target="_blank" rel="noopener">Will Serverless End the Dominance of Linux in the Cloud? &lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Firecracker: Lightweight Virtualization for Serverless Applications</title><link>https://vjabrayilov.github.io/post/firecracker/</link><pubDate>Thu, 21 Jul 2022 00:00:00 +0000</pubDate><guid>https://vjabrayilov.github.io/post/firecracker/</guid><description>&lt;ul>
&lt;li>&lt;a href="#summary">Summary&lt;/a>&lt;/li>
&lt;li>&lt;a href="#background">Background&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#virtualization">Virtualization&lt;/a>&lt;/li>
&lt;li>&lt;a href="#lambda">Lambda&lt;/a>&lt;/li>
&lt;li>&lt;a href="#interesting-points">Interesting points&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#references">References&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="summary">Summary&lt;/h2>
&lt;ul>
&lt;li>Firecracker is a high-performance virtualization solution built to run Amazon’s serverless applications securely and with minimal resources. It now does so at immense scale.&lt;/li>
&lt;/ul>
&lt;h2 id="background">Background&lt;/h2>
&lt;h3 id="virtualization">Virtualization&lt;/h3>
&lt;ul>
&lt;li>Initially, a separate VM per Lambda customer, but existing VM solutions required significant resources, hence resulting in non-optimal utilization.&lt;/li>
&lt;li>2 types of hypervisors
&lt;ul>
&lt;li>Type 1
&lt;ul>
&lt;li>directly integrated in the hardware&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Type 2
&lt;ul>
&lt;li>run an operating system on top of the hardware, then run the hypervisor on top of that operating system&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://www.micahlerner.com/assets/firecracker/Hypervisor.svg" alt="https://www.micahlerner.com/assets/firecracker/Hypervisor.svg" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;ul>
&lt;li>Linux has a hypervisor built into the kernel - Kernel Virtual Machine, arguably a &lt;em>Type 1&lt;/em> hypervisor.&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://www.kernel.org/doc/ols/2007/ols2007v1-pages-225-230.pdf" target="_blank" rel="noopener">ols2007v1-pages-225-230.pdf&lt;/a>&lt;/p>
&lt;ul>
&lt;li>&lt;strong>virtio&lt;/strong> (linux provided interface) allows the user space kernel components to interact with the host OS. Rather than passing all interactions with a guest kernel directly to the host kernel, some functions (particularly, device interactions) go from a guest kernel to a virtual machine monitor (a.k.a VMM) (a popular example: QEMU)&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://www.usenix.org/legacy/publications/library/proceedings/usenix05/tech/freenix/full_papers/bellard/bellard.pdf" target="_blank" rel="noopener">bellard.pdf&lt;/a>&lt;/p>
&lt;ul>
&lt;li>Cons(-) of QEMU:
&lt;ul>
&lt;li>significant amount of code ⇒ more code, more potential attack surface&lt;/li>
&lt;li>redundant functionality, that Lambda would never use: such as support for USB drivers&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>So, &lt;strong>crosvm&lt;/strong> is chosen (a VMM open-sourced by Google and developed for ChromeOS)
&lt;a href="https://prilik.com/blog/post/crosvm-paravirt/" target="_blank" rel="noopener">Paravirtualized Devices in crosvm - a Performance Panacea for Modern VMs&lt;/a>&lt;/li>
&lt;/ul>
&lt;h3 id="lambda">Lambda&lt;/h3>
&lt;ul>
&lt;li>When a lambda is invoked, the ensuing HTTP request hits an AWS Load Balancer.&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://www.micahlerner.com/assets/firecracker/arch.png" alt="https://www.micahlerner.com/assets/firecracker/arch.png" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;ul>
&lt;li>4 main components:
&lt;ul>
&lt;li>Workers
&lt;ul>
&lt;li>the component running lambda’s code&lt;/li>
&lt;li>each runs many MicroVMs in “slots” and other services schedule code to be run in the MicoVMs when a lambda is invoked&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Frontend
&lt;ul>
&lt;li>entrance into the lambda system&lt;/li>
&lt;li>receives invoke requests and communicate with Worker Manager to determine where to run the lambda. then directly communicates with the Workers&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Worker Manager
&lt;ul>
&lt;li>ensures that the same lambda is routed to the same set of Workers&lt;/li>
&lt;li>keep tracks of where a lambda has been scheduled previously&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Placement service
&lt;ul>
&lt;li>makes scheduling decisions to assign a lambda invocation to a worker&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Lambda Worker Architecture
&lt;ul>
&lt;li>Firecracker VM&lt;/li>
&lt;li>Shim process
&lt;ul>
&lt;li>process inside of the VM that communicates with an external side car called the Micro Manager&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Micro Manager
&lt;ul>
&lt;li>a sidecar communicating over TCP with a Shim process&lt;/li>
&lt;li>reports metadata received back to the Placement service&lt;/li>
&lt;li>can be called from the Frontend to invoke a specific function&lt;/li>
&lt;li>on the function completion, receives the response from the shim process passing back to the client as needed&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://www.micahlerner.com/assets/firecracker/lambdaworker.png" alt="https://www.micahlerner.com/assets/firecracker/lambdaworker.png" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="interesting-points">Interesting points&lt;/h3>
&lt;ul>
&lt;li>Only IO performance was inferior, and they argue that causes are no flushing to disk and an implementation of block IOs which performs IO serially; async IO support with io_uring can resolve it, there is an issue about it in github.&lt;/li>
&lt;/ul>
&lt;p>&lt;a href="https://github.com/firecracker-microvm/firecracker/issues/1600" target="_blank" rel="noopener">[Perf] Implement async IO for the block device using io_uring · Issue #1600 · firecracker-microvm/firecracker&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://unixism.net/loti/what_is_io_uring.html" target="_blank" rel="noopener">Lord of the io_uring&lt;/a>&lt;/p>
&lt;h2 id="references">References&lt;/h2>
&lt;ul>
&lt;li>blog post: &lt;a href="https://www.micahlerner.com/2021/06/17/firecracker-lightweight-virtualization-for-serverless-applications.html" target="_blank" rel="noopener">Firecracker: Lightweight Virtualization for Serverless Applications&lt;/a>&lt;/li>
&lt;li>paper: (&lt;a href="https://www.usenix.org/conference/nsdi20/presentation/agache" target="_blank" rel="noopener">https://www.usenix.org/conference/nsdi20/presentation/agache&lt;/a>)&lt;/li>
&lt;/ul></description></item></channel></rss>